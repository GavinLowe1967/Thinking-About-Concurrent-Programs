\subsection{Tuning experiments}

Figure~\ref{fig:bag-of-tasks-experiment} shows timing results for the
bag-of-tasks example.  Each plot considers a particular choice for the number
of intervals, |n|, and the number of tasks, |nTasks|.  The x-axis considers
different numbers of workers, and the y-axis gives the times taken.  Each run
used unbounded buffered channels.  Each observation performed $2^{27}/\sm{n}$
runs.

%%%%%

\begin{figure}
\begin{center}
\input{trapeziumBagNumsWorkersExperiment}
\end{center}
\caption{Experiments on the bag-of-tasks example.}
\label{fig:bag-of-tasks-experiment}
\end{figure}

%%%%%

It is useful to consider the quantity $\sm n / \sm{nTasks}$ for each plot,
i.e.~the number of intervals per tasks, which runs from $2^9$ to $2^{13}$ by
factors of~$2$.  This is a good measure of the computational cost of each
task.   For smaller values of this measure, the program achieves poor scaling,
being slower for eight workers than for four.  This is consistent with what we
saw earlier: the low computational cost of each task means that the channels
become congested.  However, for higher values of this measure, the program
scales better.  

%%%%%

Figure~\ref{fig:bag-of-tasks-experiment-2} gives results for experiments
considering the number of tasks to give each worker.  Each run used eight
workers, and unbounded buffered channels.  Each plot considers a particular
value for the number of intervals,~|n|.  The x-axis gives the average number
of tasks per worker.  Each observation is based on $2^{28}/\sm{n}$ runs.

\begin{figure}
% scala  tacp.trapezium.TrapeziumExperiment --doBagNumTasks --strict
\begin{center}
\input{trapeziumBagExperiment}
\end{center}
\caption{Experiments on the bag-of-tasks example, considering the number of
  tasks per worker.}
\label{fig:bag-of-tasks-experiment-2}
\end{figure}

Each plot shows a decrease in time as the number of tasks per worker increases
from two to about sixteen.  Having more tasks allows for better load
balancing.  However, beyond a certain point, increasing the number of tasks
makes the program slower: at this point, the channel communication is becoming
a bottleneck again.

Most of the plots show that using an average of two tasks per worker is slower
than just one, which may seem surprising.  I investigated this by arranging
for each worker to print the number of tasks it processed.  When the average
is one task per worker, it is nearly always the case that each worker indeed
executes exactly one task; the difference in times taken by workers is not
very large in this case.  However, when the average is two tasks per worker,
it is normally the case that at least one (slow) worker performs only one
task, and so another worker performs three; the latter worker therefore takes
considerably longer than the others, and this increases the overall running
time.

It is worth noting that each of the plots has a fairly wide U-shape.  For the
lower three plots, there is little difference between $2^4$ and $2^7$ tasks
per worker.  This is a good situation, as it suggests the program is fairly
stable with respect to changes in speed of workers, for example caused by
different hardware. 

Experiments on the 32-core server gave similar results, except in order to
benefit from the additional machine threads, each task needs to be larger.

% \framebox{casteret}

