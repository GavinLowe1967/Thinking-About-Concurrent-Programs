A common pattern in concurrent systems is that of clients and servers.
A~\emph{server} is a thread or process that repeatedly handles requests from
\emph{client}s.

The client-server pattern is particularly prevalent in distributed systems,
where communications are over a network, such as the Internet.  For example,
consider a web server that services requests from web clients (e.g.~web
browsers), or a networked file server that services requests from user
programs to read and write files.

The client-server pattern is also used in the implementation of some
operating systems, e.g.~Minix.  Various servers run within the operating
system, for example to provide access to the file system or the terminal.  The
advantage of this approach is one of modularisation.  Each server can be
considered a separate program, which means that the operating system kernel
can be rather small.  This approach is more straightforward than a monolithic
operating system that incorporates many features and services.

The first half of this chapter will consider a server that is responsible for
allocating some type of resource to clients, similar to the type of server in
an operating system.  We will use this example to study different ways of
structuring such a client-server mechanism.

We will mainly use the client-server pattern to implement a module within a
larger program.  We have already seen this
approach several times: for example, in the bag-of-tasks examples, the bag was
implemented as a server that received requests from workers (clients) for
tasks.
 
A \emph{synchronisation object} is an object that allows two (or more) threads
to synchronise and exchange data.  By \emph{synchronise}, we mean that the
threads execute the operations at the same time: more precisely, there is an
overlap between the time periods during which the threads execute their
operations.  Synchronisation is a useful tool in coordinating threads. 

Towards the end of this chapter we will use a client-server pattern to
implement two \emph{synchronisation objects}: an \emph{exchanger} that allows
two threads to exchange data; and a \emph{filter channel} that is like a
synchronous channel, but allows the receiver to specify a property that must
be satisfied by the value it receives.  We will also consider how to test
these objects: testing synchronisation objects often requires some ingenuity.

In Chapter~\ref{chap:datatypes}, we will study how to use a client-server
architecture to implement a \emph{concurrent datatype}: an object that acts
much like a sequential datatype, such as a queue or a mapping, but provides
client code with thread-safe operations on the datatype. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{A resource allocation server}

We consider the example of a server that is responsible for managing and
allocating multiple resources of the same kind.  Such servers are common in
operating systems, where the resources might be memory or file blocks.
However, the pattern is more widely applicable.  Clients acquire resources for
use, and later return them to the server.

One problem we need to address is: what should happen if a client requests a
resource and there is none available?  In this section, we return a special
value to indicate that no resource is available.  More precisely, we use an
|Option[Resource]| value: the client receives a value |Some(r)| to indicate
that resource |r| has been acquired, or the value |None| to indicate that no
resource is available.
%
In the latter case, it is up to the client to decide what to do: it might try
again later, or might throw an exception.  
%
An alternative approach would be for the server to queue the request until it
can be serviced; we will consider this approach later in the chapter.

%%%%%

\begin{figure}
\begin{scala}
object RAServer{
  /** Client identities. */
  type ClientId = Int

  /** Resource identities. */
  type Resource = Int
}

import RAServer._

/** A resource server. */
trait RAServer{
  /** Request a resource. */
  def requestResource(me: ClientId): Option[Resource]

  /** Return a resource. */
  def returnResource(me: ClientId, r: Resource) 

  /** Shut down the server. */
  def shutdown(): Unit
} 
\end{scala}
\caption{The interface for the resource allocation module.}
\label{fig:RAServer}
\end{figure}

%%%%%

Thus we will define a server that extends the trait |RAServer| in
Figure~\ref{fig:RAServer}.  We represent resources by |Int|s, and we also
assume each client has an |Int| identity, which they include in operation
calls.  There are operations for a client to obtain a resource, or to return a
resource.  There is also an operation to shut down the server (although this
could be considered optional).

%%%%% First implementation

The first implementation is in Figures~\ref{fig:RAServer1-1}
and~\ref{fig:RAServer1-2}.  We assume here that clients have identities in the
range $\interval0{\sm{clients}}$, and resources have identities in the range
$\interval0{\sm{numResources}}$, where |clients| and |numResources| are known
in advance.

%%%%%

\begin{figure}
\begin{scala}
/** A resource server. 
  * This version assumes the number of clients is known initially. 
  * @param £clients£ the number of clients.
  * @param £numResources£ the number of resources.  */
class RAServer1(clients: Int, numResources: Int) extends RAServer{

  /* Channel for requesting a resource. */
  private val acquireRequestChan = new SyncChan[ClientId]

  /* Channels for optionally returning a resouce, indexed by client identities. */
  private val acquireReplyChan = 
    Array.fill(clients)(new SyncChan[Option[Resource]])

  /* Channel for returning a resource. */
  private val returnChan = new SyncChan[Resource]

  /* Channel for shutting down the server. */
  private val shutdownChan = new SyncChan[Unit]

  /** Request a resource. */
  def requestResource(me: ClientId): Option[Resource] = {
    acquireRequestChan!me  // Send request.
    acquireReplyChan(me)?() // Wait for response.
  }

  /** Return a resource. */
  def returnResource(me: ClientId, r: Resource) = returnChan!r

  /** Shut down the server. */
  def shutdown() = shutdownChan!()

  private def server = thread("server"){ ...  } // See Figure £\ref{fig:RAServer1-2}£.

  fork(server)
}
\end{scala}
\caption{The first implementation of the resource allocation module (part~1).}
\label{fig:RAServer1-1} 
\end{figure}

%%%%%

To request a resource, a client sends a message on channel
|acquire|\-|Request|\-|Chan|; this channel is shared between all clients.  It
then receives a reply from the server, which is the result of the operation.
In this version, we assume one channel per client, in array
|acquireReplyChan|; this ensures that the expected client receives the
resource.

To return a resource, the client simply sends the resource's identity on the
channel |returnChan|.  Likewise, to shut down the server, a message is sent on
the channel |shutDownChan|.

%%%%%

\begin{figure}
\begin{scala}
  private def server = thread("server"){
    // Record whether resource £i£ is available in £free(i)£.
    val free = Array.fill(numResources)(true); var done = false
    serve(!done)(
      acquireRequestChan =?=> { c => 
	// Find free resource.
	var r = 0
	while(r < numResources && !free(r)) r += 1
	if(r == numResources) acquireReplyChan(c)!None
        else{  // Pass resource £r£ back to client £c£.
	  free(r) = false; acquireReplyChan(c)!Some(r)
        }
      }
      | returnChan =?=> { r => free(r) = true }
      | shutdownChan =?=> { _ => done = true }
    )
    acquireRequestChan.close(); returnChan.close(); shutdownChan.close()
  }
\end{scala}
\caption{The first implementation of the resource allocation module: the
  server}
\label{fig:RAServer1-2}
\end{figure}

%%%%%

The server (Figure~\ref{fig:RAServer1-2}) keeps track of the resources that are
currently free in an array \SCALA{free}.  Note that |free| is declared as a
local variable within the definition of~|server|.  This ensures that only the
server has access to |free|, which avoids race conditions. This also clarifies
the intended use of~|free|: if we had declared it as an object variable, it
would have been less clear, as it would look like a shared variable.

The main loop is defined using a |serve| with a boolean guard |!done|, so it
will terminate when |done| is true.  On each iteration, it is willing to
receive a message on any of its input channels.  If it receives a request for
a resource from client~|c|, it performs a straightforward search through
|free|, and returns a suitable reply to~|c|, updating |free| if appropriate.
If it receives a returned resource, is simply updates |free| to mark that
resource as free.  If it receives a shutdown message, it sets |done| to true
to exit the loop, at which point it closes its input channels to signal to
clients.

\begin{instruction}
Study the details of the implementation. 
\end{instruction}

Above, we chose to use different channels for acquiring and returning a
resource or shutting down the server.  An alternative is to use a single
channel that can pass different types of request.  Such an approach seems more
natural in a networked application.  In the resource allocation module, we
could define the following (Scala box~\ref{sb:case-classes} describes case
classes):
%
\begin{scala}
  private trait Request
  private case class Acquire(c: ClientId) extends Request // Acquire a resource.
  private case class Return(r: Resource) extends Request // Return a resource.
  private case object Shutdown extends Request // Shut down the server.
  private val requestChan = new SyncChan[Request] // Channel for requests.
\end{scala}
%
The server would then receive on |requestChan|, and pattern match on the value
received (see Scala box~\ref{sb:pattern-matching}):
%
\begin{scala}
  requestChan?() match{
    case Acquire(c) => ...
    case Return(r) => ...
    case Shutdown => ...
  }
\end{scala}
