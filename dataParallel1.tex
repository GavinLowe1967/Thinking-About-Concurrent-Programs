In this chapter we will study a particular style of data parallel programming
where the threads proceed \emph{synchronously}.  The program proceeds in
\emph{rounds}; in each round, each thread performs some computation.  However,
at the end of each round, each thread needs to wait for the other threads to
finish that round before they all proceed to the next: this requires a global
synchronisation.

%%%%%

Typically, each thread will operate on one section of the data, but  may
need to read data updated by other threads.  The synchronisation can be used
to ensure that one thread obtains the updates to the data made by other
threads on the previous round.

The data can be distributed between threads by two different techniques.
%
\begin{itemize}
\item
By sending messages; this works well when each piece of data has to be
passed to only a few other threads;

\item
By writing to shared variables.
\end{itemize}

%These algorithms are sometimes known as heart-beat algorithms.

%%%%%

Applications include: image processing, where different threads operate on
different parts of the image; solving differential equations, for example in
weather forecasting or fluid dynamics, where different threads operate on
different areas; or matrix calculations, where different threads operate on
different parts of the matrix.  Most of this chapter will be devoted to giving
examples of this style of programming. 

%%%%%

The global synchronisation at the end of each round is sometimes known as a
\emph{barrier synchronisation}, since it represents a barrier than no thread
may pass until all have reached that point.

Suppose we have |p| threads with identities $\interval{\sm 0}{\sm p}$.  Then a
suitable barrier synchronisation object may be created in SCL by:
%
\begin{scala}
  val barrier = new Barrier(p)
\end{scala}
%
A thread with identity~|me| performs the barrier synchronisation by executing%
%
\begin{scala}
  barrier.sync(me)
\end{scala}
%
No call to \SCALA{sync} will return until all \SCALA{p} threads have called
it. 

%%%%%


Figure~\ref{fig:serverBarrier} gives a possible implementation of a barrier
using a server.  The server waits to receive a message on channel |arrive|
from each of the |p|~threads before sending then a message on channel~|leave|,
telling them they can continue.

\begin{figure}[htb]
\begin{scala}
class ServerBarrier(p: Int){
  private val arrive = new SyncChan[Unit]
  private val leave = new SyncChan[Unit]

  def sync(me: Int) = { arrive!(); leave?() }

  private def server = thread{
    while(true){
      for(i <- 0 until p) arrive?()
      for(i <- 0 until p) leave!()
    }
  }

  fork(server)
}
\end{scala}
\caption{A simple implementation of a barrier synchronisation.}
\label{fig:serverBarrier}
\end{figure}

The above implementation means that each synchronisation takes time $O(\sm p)$,
assuming all the threads call |sync| at the same time.  In fact, the
implementation in SCL is more sophisticated, and allows each synchronisation
to take time $O(\log \sm p)$.  Exercise~\ref{ex:barrierLog} asks you to
implement a barrier with this property.

One important feature of a barrier synchronisation is that it also ensures
cache consistency between different threads.  If one thread writes to a shared
variable before a synchronisation, and another thread reads that variable
after the synchronisation, then the read is guaranteed to see the effects of
the write.  Further, compiler optimisations are not allowed to break this
property.  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Example: simulating astronomical bodies}


In this section we illustrate this style of synchronous programming by
implementing a concurrent simulation of astronomical bodies, such as stars,
planets and moons, moving relative to one another under gravity.  Each
concurrent worker will be responsible for updating the state of some of the
bodies in each step of the simulation.  However, each worker will need to read
the states of all of the bodies.  We will use barrier synchronisations to
coordinate the threads and to avoid races.

We will need to record the position and velocity of each astronomical body.
Each of these is a vector in three-dimensional space.  The support class
|Vector|, in Figure~\ref{fig:vector}, models such vectors.

%%%%%

\begin{figure}
\begin{scala}
/** A vector in three£-£dimensional space. */
case class Vector(x: Double, y: Double, z: Double){
  /** The length of this vector. */
  def length = Math.sqrt(x*x + y*y + z*z)

  /** This plus £v£. */
  def + (v: Vector) = Vector(x+v.x, y+v.y, z+v.z)

  /** The minus £v£. */
  def - (v: Vector) = Vector(x-v.x, y-v.y, z-v.z)

  /** This times £s£. */
  def * (s: Double) = Vector(x*s, y*s, z*s)
}

object Gravity{
  /** Gravitational constant. */
  val G = 6.6743E-11

  /** The time for one step of the simulation. */
  val Timestep = 100_000
}
\end{scala}
\caption{The class {\scalashape Vector} and the object {\scalashape Gravity}.}
\label{fig:vector}\label{fig:Gravity}
\end{figure}

%%%%%

Given two bodies, of mass $m_1$ and $m_2$ at a distance~$d$ from each other,
each exerts a force on the other of magnitude $G \times m_1 \times m_2 / d^2$,
where $G \approx 6.6743 \times 10^{-11}$ is the gravitational constant.  These
are attractive forces: the force on each body is directly towards the other.
The force on each body gives an acceperation equal to the force divided by the
body's mass.

The object |Gravity| in Figure~\ref{fig:Gravity} defines the
gravitational constant~|G|, and also the time (in seconds) represented by each
step of the simulation. 

%%%%%

\begin{figure}
\begin{scala}
/** A single astronomical body, with mass £mass£, initial position £position0£,
  * and initial velocity £velocity0£. */
class AstronomicalBody(val mass: Double, position0: Vector, velocity0: Vector){
  /** The body's current position. */
  private var position = position0

  /** The body's current velocity. */
  private var velocity = velocity0

  /** Update the velocity of this based on the gravitational attraction from
    * £other£. */
  def updateVel(other: AstronomicalBody) = {
    val towards = other.position-position // Vector to £other£.
    val d = towards.length // Distance to £other£.
    val force = Gravity.G*mass*other.mass/(d*d) // Force on this.
    val dv = towards*(force/mass/d*Gravity.Timestep) // Change in velocity.
    velocity += dv
  }

  /** Move this for one timestep.  Return the new position. */
  def move() = { position += velocity*Gravity.Timestep; position }
}
\end{scala}
\caption{The class {\scalashape
    AstronomicalBody}.} 
\label{fig:AstronomicalBody}
\end{figure}

%%%%%

Each object of the class |AstronomicalBody| represents an astronomical body.
The object records the body's mass, position and velocity.  The operation
|updateVel(other)| updates the velocity of the body based on gravitational
attraction from |other|, for one step of the simulation.  The operation |move|
updates the position of the body based on its current velocity, for one step
of the simulation, and returns the new position.

Figure~\ref{fig:SequentialSimulation} gives code for a sequential simulation.
The parameter |bodies| of the class represents the astronomical bodies to
simulate.  At each step, the velocity of each body is updated based on the
position of each other body, and then the position of each body is updated.
The simulation returns an array giving the bodies' positions at each
timestep. 

%%%%%

\begin{figure}
\begin{scala}
/** A sequential simulation for £bodies£. */
class SequentialSimulation(bodies: Array[AstronomicalBody]){
  private val n = bodies.length

  /** Simulate for £steps£ steps, returning an array of the bodies' positions at
    * each timestep. */
  def apply(steps: Int): Array[Array[Vector]] = {
    val result = Array.ofDim[Vector](steps, bodies.length)
    for(step <- 0 until steps){
      for(i <- 0 until n; j <- 0 until n; if i != j) 
        bodies(i).updateVel(bodies(j))
      for(i <- 0 until n) result(step)(i) = bodies(i).move()
    }
    result
  }
}
\end{scala}
\caption{A sequential simulation}
\label{fig:SequentialSimulation}
\end{figure}

%%%%%

\begin{instruction}
Study the implementation of the sequential simulation.
\end{instruction}

We now consider how to parallelise the simulation.  We will use a number of
workers, each of which is responsible for updating some of the astronomical
bodies.  However, we need to keep the workers synchronised: we will use a
barrier synchronisation at the end of each step, to ensure that all the
workers are on the same step at the same time.  

Further, we need to avoid race conditions.  The worker for a particular
body~|b| updates |b|'s position within the |move| operation.  However, a
different worker will read that position when it executes |b1.updateVel(b)| on
one of its own bodies~|b1|.  This is potentially a race.  In particular, if
our implementation allows these operations to happen in either order, the
results will be nondeterministic: the update to |b1| might depend on either
the previous or the new position of~|b|.

To avoid such a race, we arrange for a barrier synchronisation after all the
threads have finished the calls to |updateVel|, but before any call to
|move|.  That means that each call to |updateVel| will depend on the previous
positions of the bodies, as in the sequential program. 

The resulting concurrent simulation is in
Figure~\ref{fig:ConcurrentSimulation}.  The threads perform two barrier
synchronisations on each round, splitting the round into two subrounds.  In
the first subround, threads read the positions of bodies, and update their own
bodies' velocities.  In the second subround, threads update only their own
bodies' positions.  Thus there are no races. 

%%%%%

\begin{figure}
\begin{scala}
/** A concurrent simulation for bodies. */
class ConcurrentSimulation(bodies: Array[AstronomicalBody]){
  private val n = bodies.length

  /** Simulate for steps steps, using £numWorkers£ workers, returning an array of
    * the bodies' positions at each timestep. */
  def apply(steps: Int, numWorkers: Int): Array[Array[Vector]] = {
    // Array to hold the results.
    val result = Array.ofDim[Vector](steps,bodies.length)

    // The barrier for coordinating workers.
    val barrier = new Barrier(numWorkers)

    // A single worker.
    def worker(me: Int) = thread(s"worker($me)"){
      // This worker is responsible for £bodies[start..end)£. 
      val start = me*n/numWorkers; val end = (me+1)*n/numWorkers
      for(step <- 0 until steps){
        for(i <- start until end; j <- 0 until n; if i != j)
          bodies(i).updateVel(bodies(j))
        barrier.sync(me)
        for(i <- start until end) result(step)(i) = bodies(i).move()
        barrier.sync(me)
      }
    }

    // Run the workers. 
    run(|| (for(i <- 0 until numWorkers) yield worker(i)))
    result
  }
}
\end{scala}
\caption{The concurrent simulation.}
\label{fig:ConcurrentSimulation}
\end{figure}

\begin{instruction}
Study the implementation of the concurrent simulation.
\end{instruction}

We can test the concurrent simulation using the standard technique of
comparing it to the sequential simulation.  We generate some input data at
random, run both simulations, and compare the results. 

In previous chapters, we avoided shared variables other than read-only
variables.  We have relaxed this restriction here, but avoided races by
imposing rules on when different threads can read or write shared variables,
enforced via barrier synchronisations.  It is important to be clear about the
rules for accessing shared variables in such cases.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

