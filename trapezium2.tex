\section{Tuning}
\label{sec:trapezium-tuning}

We want to tune the program so that it runs quickly.  The main question we
want to consider is how many worker threads to use in order to minimise the
running time.
%%  A secondary question is
%% whether we should use buffered channels. 
We can run some experiments to try to obtain  a partial answer to
this question, although the answer is likely to vary with the architecture.
%
Appendix~\ref{app:experiments} describes how to run good experiments, and
explains some of the statistical terminology used below. 

We consider |n| (the number of intervals) as an input: under different
circumstances, we might want to use different values for~|n|.  We want to
understand how the optimal number of workers depends upon~|n|.

Most of the experiments in this section were run on an eight-core machine, with
two 2.40GHz Intel(R) Xeon(R) E5620 CPUs.
%
I'll also briefly mention similar experiments on a a 32-core server, with two
2.1GHz Intel(R) Xeon(R) E5-2683 CPUs with hyperthreading enabled
(hyperthreading is a hardware technique that allows a single physical core to
act like two logical cores, executing two threads concurrently).
%
In each case, the program calculated approximations to the integral 
$\int_{-100000}^{+100000} x^2 \cos x \, \mbox{d}x$.

%%%%%

Figure~\ref{fig:trapeziumExperimentLogScale} gives results for an experiment
to investigate how many workers to use.  
%
Each plot considers a particular value for |n|, given in the key.
%
The x-axis gives the number of workers used, and the y-axis gives the time
taken.  

Each \emph{observation} of the program evaluated the integral $2^{28}/\sm n$
times; that means that each observation used $2^{28}$ intervals, so the
different plots correspond to about the same amount of computation (and so fit
nicely in the same axes).  Unbounded buffered channels were used in each case.

Each data point corresponds to multiple observations of the program.  The
graph displays the mean of those observations, and a 95\% confidence interval
(see Appendix~\ref{app:experiments}).  More precisely, each point corresponds
to enough observations such that the size of the confidence interval is at
most 2\% of the mean, or 50 observations, whichever is smaller.  In fact, most
confidence intervals are too small to be plotted; and where they are plotted,
they are barely visible.

%%%%%

\begin{figure}
% scala  tacp.trapezium.TrapeziumExperiment --doLog --strict
\begin{center}
\input{trapeziumExperimentLogScale}
\end{center}
\caption{Experiment to investigate how many workers to use.}
\label{fig:trapeziumExperimentLogScale}
\end{figure}

%%%%%

Most of the plots have a U-shape.  Initially, increasing the number of workers
makes the program faster, as each worker has to consider fewer intervals.
However, beyond a particular point, increasing the number of workers becomes
counter-productive.  The aim is to find the minimum point on the curve.
U-shapes like these are very common in timing experiments.

Given that these experiments were run on a machine with eight cores, you might
have expected the program to get faster as the number of program threads
increases up to eight.  However, that isn't the case.  Consider the plot for
$\sm n = 2^{14}$.  This shows that the program is faster with two workers than
one; however, it gets slower if the number of workers is increased to~four;
and beyond that it gets much slower.  A similar phenomenon occurs with $\sm n
= 2^{16}$ and $\sm n = 2^{18}$, where the program is fastest with four
threads, but slower beyond that.  

The reason for this is that each channel is acting as a bottleneck.
Profiling, in the case of eight workers with $\sm n = 2^{14}$, shows that the
threads spend about 99\% of their time trying to send or receive values, and
only about 1\% of their time actually performing useful computation.  There is
a limit to how quickly values can be sent on the channels; the worker threads
compete with one another to send and receive.  Decreasing the number of
workers means fewer messages are sent, so the channels become less of a
bottleneck; this means that each task is larger and so takes longer, but the
benefits outweigh the disadvantages.  

The behaviour for $\sm n = 2^{20}$ and $\sm n = 2^{24}$ is much better, with
performance improving up to eight worker threads.  Profiling shows that, with
eight workers, the proportion of time threads spend trying to send or receive
is less than 40\% and less than 20\% in these cases, respectively.

Other experiments show that in cases where the channels act as a bottleneck, 
using buffered channels helps a little bit.  However, buffering makes little
difference in the well-tuned cases.
 
By the way, I ran similar experiments on the 32-core server (with 64 machine
threads).  I obtained similar results, except the channels were,
unsurprisingly, more of a bottleneck.  For values of~|n| smaller than about
$2^{28}$, the optimal number of workers was less than the 64 machine threads
available.  Put another way, in order for more machine threads to be useful,
the amount of computation done by each thread needs to be larger, so threads
spend a lower proportion of their time trying to send or receive messages. 

%% : the optimal number of workers was 64
%% only with larger values of~|n|, around~$2^{28}$.

% Code/trapeziumBuffering.tex

%% \begin{slide}
%% \label{slide:not-bag-of-tasks}
%% % scala -cp .:/home/gavinl/Scala/SCL:/home/gavinl/Scala/Util
%% % TrapeziumExperiment  --buffering 16 --doLog --strict --server on casteret
%% \begin{tikzpicture}
%% \begin{semilogxaxis}[
%% %  title = Timing experiment on the numerical integration example,
%%   ylabel = Time (ms),
%%   legend pos = north west,
%%   height = 0.98\textheight,
%%   width = 0.9\textwidth,
%%   scaled ticks = false,
%%   xlabel = Number of workers,
%%   xmin = 1,
%%   ymin = 0,
%%   ymax = 12000,
%%   log basis x=2
%% ]
%% \input{trapeziumExperimentLogScaleBody}
%% \end{semilogxaxis}
%% \end{tikzpicture}
%% \end{slide}

